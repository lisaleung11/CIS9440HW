{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Question Dimension\n",
    "\n",
    "# Mapping dictionary\n",
    "question_mapping = {\n",
    "    'Q01': 'Percentage of older adults who are eating 2 or more fruits daily',\n",
    "    'Q02': 'Percentage of older adults who are eating 3 or more vegetables daily',\n",
    "    'Q03': 'Percentage of older adults who are experiencing frequent mental distress',\n",
    "    'Q04': 'Percentage of older adults who have been told they have high blood pressure who report currently taking medication for their high blood pressure',\n",
    "    'Q05': 'Percentage of older adults who have fallen and sustained an injury within last year',\n",
    "    'Q07': 'Percentage of older adults who report having lost 5 or fewer teeth due to decay or gum disease',\n",
    "    'Q08': 'Physically unhealthy days (mean number of days in past month)',\n",
    "    'Q09': 'Percentage of at risk adults (have diabetes, asthma, cardiovascular disease or currently smoke) who ever had a pneumococcal vaccine',\n",
    "    'Q10': 'Percentage of older adult men who are up to date with select clinical preventive services',\n",
    "    'Q11': 'Percentage of older adult women who are up to date with select clinical preventive services',\n",
    "    'Q12': 'Percentage of older adult women who have received a mammogram within the past 2 years',\n",
    "    'Q13': 'Percentage of older adults who are currently obese, with a body mass index (BMI) of 30 or more',\n",
    "    'Q14': 'Percentage of older adults who had a cholesterol screening within the past 5 years',\n",
    "    'Q15': 'Percentage of older adults who had either a home blood stool test within the past year or a sigmoidoscopy or colonoscopy within the past 10 years',\n",
    "    'Q16': 'Percentage of older adults who have not had any leisure time physical activity in the past month',\n",
    "    'Q17': 'Percentage of older adults who have smoked at least 100 cigarettes in their entire life and still smoke every day or some days',\n",
    "    'Q18': 'Percentage of older adults who reported influenza vaccine within the past year',\n",
    "    'Q19': 'Percentage of older adults without diabetes who reported a blood sugar or diabetes test within 3 years',\n",
    "    'Q20': 'Percentage of older adult women with an intact cervix who had a Pap test within the past 3 years',\n",
    "    'Q21': 'Percentage of older adults who reported binge drinking within the past 30 days',\n",
    "    'Q22': 'Percentage of older adults who have ever been told by a health professional that they have high blood pressure',\n",
    "    'Q27': 'Percentage of older adults with a lifetime diagnosis of depression',\n",
    "    'Q30': 'Percentage of older adults who reported subjective cognitive decline or memory loss that is happening more often or is getting worse in the preceding 12 months',\n",
    "    'Q31': 'Percentage of older adults who reported subjective cognitive decline or memory loss that interferes with their ability to engage in social activities or household chores',\n",
    "    'Q32': 'Percentage of older adults who self-reported that their health is \"fair\" or \"poor\"',\n",
    "    'Q33': 'Percentage of older adults who self-reported that their health is \"good\", \"very good\", or \"excellent\"',\n",
    "    'Q34': 'Percentage of older adults getting sufficient sleep (>6 hours)',\n",
    "    'Q35': 'Mean number of days with activity limitations in the past month',\n",
    "    'Q36': 'Percentage of older adults who provided care for a friend or family member within the past month',\n",
    "    'Q37': 'Percentage of older adults currently not providing care who expect to provide care for someone with health problems in the next two years',\n",
    "    'Q38': 'Percentage of older adults who provided care to a friend or family member for six months or more',\n",
    "    'Q39': 'Average of 20 or more hours of care per week provided to a friend or family member',\n",
    "    'Q40': 'Percentage of older adults who provided care for someone with dementia or other cognitive impairment within the past month',\n",
    "    'Q41': 'Percentage of older adults who reported that as a result of subjective cognitive decline or memory loss that they need assistance with day-to-day activities',\n",
    "    'Q42': 'Percentage of older adults with subjective cognitive decline or memory loss who reported talking with a health care professional about it',\n",
    "    'Q43': 'Percentage of older adults ever told they have arthritis',\n",
    "    'Q44': 'Severe joint pain due to arthritis among older adults with doctor-diagnosed arthritis',\n",
    "    'Q45': 'Fair or poor health among older adults with doctor-diagnosed arthritis',\n",
    "    'Q46': 'Percentage of older adults who report having a disability (includes limitations related to sensory or mobility impairments or a physical, mental, or emotional condition)'\n",
    "}\n",
    "\n",
    "unique_question_ids = df_cleaned['QuestionID'].unique()\n",
    "# Converting the array of unique values into a DataFrame\n",
    "unique_question_df = pd.DataFrame(unique_question_ids, columns=['question_id'])\n",
    "\n",
    "# Applying the mapping to create a new column with descriptions\n",
    "unique_question_df['question_desc'] = unique_question_df['question_id'].map(question_mapping)\n",
    "unique_question_df = unique_question_df[unique_question_df['question_id'] != '<NA>']\n",
    "unique_question_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Class Dimension\n",
    "\n",
    "# Mapping dictionary\n",
    "class_mapping = {\n",
    "    'C01': 'Overall Health',\n",
    "    'C02': 'Nutrition/Physical Activity/Obesity',\n",
    "    'C03': 'Screenings and Vaccines',\n",
    "    'C04': 'Smoking and Alcohol Use',\n",
    "    'C05': 'Mental Health',\n",
    "    'C06': 'Cognitive Decline',\n",
    "    'C07': 'Caregiving'\n",
    "}\n",
    "\n",
    "unique_class_ids = df_cleaned['ClassID'].unique()\n",
    "# Converting the array of unique values into a DataFrame\n",
    "unique_class_df = pd.DataFrame(unique_class_ids, columns=['class_id'])\n",
    "\n",
    "# Applying the mapping to create a new column with descriptions\n",
    "unique_class_df['class_desc'] = unique_class_df['class_id'].map(class_mapping)\n",
    "unique_class_df = unique_class_df[unique_class_df['class_id'] != '<NA>']\n",
    "unique_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Topic Dimension\n",
    "\n",
    "# Mapping dictionary\n",
    "topic_mapping = {\n",
    "    'TOC11': 'Arthritis among older adults',\n",
    "    'TAC03': 'Binge drinking within past 30 days',\n",
    "    'TSC06': 'Cholesterol checked in past 5 years',\n",
    "    'TSC02': 'Colorectal cancer screening',\n",
    "    'TAC01': 'Current smoking',\n",
    "    'TSC04': 'Diabetes screening within past 3 years',\n",
    "    'TOC10': 'Disability status, including sensory or mobility limitations',\n",
    "    'TGC03': 'Duration of caregiving among older adults',\n",
    "    'TNC01': 'Eating 2 or more fruits daily',\n",
    "    'TNC02': 'Eating 3 or more vegetables daily',\n",
    "    'TSC09': 'Ever had pneumococcal vaccine',\n",
    "    'TGC02': 'Expect to provide care for someone in the next two years',\n",
    "    'TOC13': 'Fair or poor health among older adults with arthritis',\n",
    "    'TOC06': 'Fall with injury within last year',\n",
    "    'TMC01': 'Frequent mental distress',\n",
    "    'TCC02': 'Functional difficulties associated with subjective cognitive decline or memory loss among older adults',\n",
    "    'TSC07': 'High blood pressure ever',\n",
    "    'TSC08': 'Influenza vaccine within past year',\n",
    "    'TGC04': 'Intensity of caregiving among older adults',\n",
    "    'TMC03': 'Lifetime diagnosis of depression',\n",
    "    'TSC01': 'Mammogram within past 2 years',\n",
    "    'TCC03': 'Need assistance with day-to-day activities because of subjective cognitive decline or memory loss',\n",
    "    'TNC03': 'No leisure-time physical activity within past month',\n",
    "    'TNC04': 'Obesity',\n",
    "    'TOC05': 'Oral health:  tooth retention',\n",
    "    'TSC03': 'Pap test within past 3 years',\n",
    "    'TOC01': 'Physically unhealthy days (mean number of days)',\n",
    "    'TOC09': 'Prevalence of sufficient sleep',\n",
    "    'TGC01': 'Provide care for a friend or family member in past month',\n",
    "    'TGC05': 'Provide care for someone with cognitive impairment within the past month',\n",
    "    'TOC03': 'Recent activity limitations in past month',\n",
    "    'TOC07': 'Self-rated health (fair to poor health)',\n",
    "    'TOC08': 'Self-rated health (good to excellent health)',\n",
    "    'TOC12': 'Severe joint pain among older adults with arthritis',\n",
    "    'TCC01': 'Subjective cognitive decline or memory loss among older adults',\n",
    "    'TOC04': 'Taking medication for high blood pressure',\n",
    "    'TCC04': 'Talked with health care professional about subjective cognitive decline or memory loss',\n",
    "    'TSC10': 'Up-to-date with recommended vaccines and screenings - Men',\n",
    "    'TSC11': 'Up-to-date with recommended vaccines and screenings - Women'\n",
    "}\n",
    "\n",
    "unique_topic_ids = df_cleaned['TopicID'].unique()\n",
    "# Converting the array of unique values into a DataFrame\n",
    "unique_topic_df = pd.DataFrame(unique_topic_ids, columns=['topic_id'])\n",
    "\n",
    "# Applying the mapping to create a new column with descriptions\n",
    "unique_topic_df['topic_desc'] = unique_topic_df['topic_id'].map(topic_mapping)\n",
    "unique_topic_df = unique_topic_df[unique_topic_df['topic_id'] != '<NA>']\n",
    "unique_topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from io import StringIO\n",
    "import os\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import pandas as pd\n",
    "from io import BytesIO, StringIO\n",
    "import sqlalchemy\n",
    "\n",
    "# Azure Functions\n",
    "\n",
    "\n",
    "def azure_upload_blob(connect_str, container_name, blob_name, data):\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "    blob_client.upload_blob(data, overwrite=True)\n",
    "    print(f\"Uploaded to Azure Blob: {blob_name}\")\n",
    "\n",
    "\n",
    "def azure_download_blob(connect_str, container_name, blob_name):\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "    download_stream = blob_client.download_blob()\n",
    "    return download_stream.readall()\n",
    "\n",
    "\n",
    "URL = \"https://data.cdc.gov/api/views/hfr9-rurv/rows.csv?accessType=DOWNLOAD\"\n",
    "\n",
    "response = requests.get(URL, verify=False)\n",
    "if response.status_code == 200:\n",
    "    # Decode the content and read into DataFrame\n",
    "    df_raw = pd.read_csv(BytesIO(response.content))\n",
    "    # Print the first few rows to verify if the data has been read successfully\n",
    "    print(df_raw.head())\n",
    "    print(df_raw.columns)\n",
    "    print(df_raw.shape)\n",
    "    df_raw.info()\n",
    "else:\n",
    "    print(\"Failed to download the file.\")\n",
    "\n",
    "df_cleaned = df_raw.copy()\n",
    "df_cleaned = df_raw.drop(columns=  ['LocationAbbr','Data_Value_Footnote_Symbol','Data_Value_Footnote','Datasource','Data_Value_Unit','Data_Value_Alt','StratificationCategory1','StratificationCategoryID1','StratificationID1','StratificationCategoryID2','StratificationID2'])\n",
    "df_cleaned = df_cleaned.dropna(subset=['Data_Value'])\n",
    "df_cleaned.info()\n",
    "\n",
    "df_cleaned['Longitude'] = None\n",
    "df_cleaned['Latitude'] = None\n",
    "\n",
    "for index, row in df_cleaned.iterrows():\n",
    "    geolocation = row['Geolocation']\n",
    "    if geolocation:\n",
    "        match = re.match(r'POINT \\(([-0-9.]+) ([-0-9.]+)\\)', geolocation)\n",
    "        if match:\n",
    "            longitude = float(match.group(1))\n",
    "            latitude = float(match.group(2))\n",
    "            df_cleaned.at[index, 'Longitude'] = longitude\n",
    "            df_cleaned.at[index, 'Latitude'] = latitude\n",
    "\n",
    "alzheimer_df = df_cleaned.copy()\n",
    "\n",
    "alzheimer_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_raw.copy()\n",
    "df_cleaned = df_raw.drop(columns=  ['LocationAbbr','Data_Value_Footnote_Symbol','Data_Value_Footnote','Datasource','Data_Value_Unit','Data_Value_Alt','StratificationCategory1','StratificationCategoryID1','StratificationID1','StratificationCategoryID2','StratificationID2'])\n",
    "df_cleaned = df_cleaned.dropna(subset=['Data_Value'])\n",
    "df_cleaned.info()\n",
    "\n",
    "df_cleaned['Longitude'] = None\n",
    "df_cleaned['Latitude'] = None\n",
    "\n",
    "for index, row in df_cleaned.iterrows():\n",
    "    geolocation = row['Geolocation']\n",
    "    if isinstance(geolocation, float):\n",
    "        continue  # Skip float values\n",
    "    if geolocation:\n",
    "        match = re.match(r'POINT \\(([-0-9.]+) ([-0-9.]+)\\)', geolocation)\n",
    "        if match:\n",
    "            longitude = float(match.group(1))\n",
    "            latitude = float(match.group(2))\n",
    "            df_cleaned.at[index, 'Longitude'] = longitude\n",
    "            df_cleaned.at[index, 'Latitude'] = latitude\n",
    "\n",
    "alzheimer_df = df_cleaned.copy()\n",
    "\n",
    "alzheimer_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value = df_cleaned[df_cleaned['Data_Value_Type'] == 'Mean']['Data_Value'].mean()\n",
    "\n",
    "# Filter out rows where 'Data_Value' is equal to the mean\n",
    "percent_df = df_cleaned[df_cleaned['Data_Value'] != mean_value]\n",
    "\n",
    "new_column_names = {\n",
    "    'RowId': 'fact_id',\n",
    "\t'Data_Value':'data_value',\n",
    "\t'Low_Confidence_Limit': 'low_confidence_limit',\n",
    "\t'High_Confidence_Limit': 'high_confidence_limit',\n",
    "\t'TopicID': 'topic_id',\n",
    "\t'ClassID': 'class_id', \n",
    "\t'QuestionID': 'question_id',\n",
    "    'LocationID': 'location_id',\n",
    "    'YearStart': 'year_start',\n",
    "    'YearEnd': 'year_end',\n",
    "    'StratificationID1': 'stratification1_id',\n",
    "    'StratificationID2': 'stratification2_id',\n",
    "    'StratificationCategoryID2': 'stratification_categoryID2'\n",
    "}\n",
    "\n",
    "percent_df = percent_df.rename(columns=new_column_names)\n",
    "new_order = ['fact_id', 'data_value', 'low_confidence_limit', 'high_confidence_limit', 'location_id', 'topic_id', 'class_id', 'year_start', 'year_end','question_id','stratification1_id','stratification2_id','stratification_categoryID2']\n",
    "percent_df = percent_df[new_order]\n",
    "percent_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratification_category2_df = df_cleaned[['StratificationCategoryID2', 'StratificationCategory2']]\n",
    "\n",
    "# Dropping duplicates to get unique QuestionID pairs with questions\n",
    "unique_stratification_category2_df = stratification_category2_df.drop_duplicates()\n",
    "\n",
    "# Mapping dictionary\n",
    "stratification_category2_mapping = dict(zip(unique_stratification_category2_df['StratificationCategoryID2'], unique_stratification_category2_df['StratificationCategory2']))\n",
    "\n",
    "# Applying the mapping to create a new column with descriptions\n",
    "df_cleaned['stratification_category2'] = df_cleaned['StratificationCategoryID2'].map(stratification_category2_mapping)\n",
    "unique_stratification_category2_df = unique_stratification_category2_df.rename(columns={'StratificationCategoryID2': 'stratification_categoryID2', 'StratificationCategory2': 'stratification_category2'})\n",
    "unique_stratification_category2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratification2_df = df_cleaned[['StratificationID2', 'Stratification2']]\n",
    "\n",
    "# Dropping duplicates to get unique QuestionID pairs with questions\n",
    "unique_stratification2_df = stratification2_df.drop_duplicates()\n",
    "\n",
    "# Mapping dictionary\n",
    "stratification2_mapping = dict(zip(unique_stratification2_df['StratificationID2'], unique_stratification2_df['Stratification2']))\n",
    "\n",
    "# Applying the mapping to create a new column with descriptions\n",
    "df_cleaned['stratification2'] = df_cleaned['StratificationID2'].map(stratification2_mapping)\n",
    "unique_stratification2_df = unique_stratification2_df.rename(columns={'StratificationID2': 'stratification2_id', 'Stratification1': 'stratification2'})\n",
    "unique_stratification2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratification1_df = df_cleaned[['StratificationID1', 'Stratification1']]\n",
    "\n",
    "# Dropping duplicates to get unique QuestionID pairs with questions\n",
    "unique_stratification1_df = stratification1_df.drop_duplicates()\n",
    "\n",
    "# Mapping dictionary\n",
    "stratification1_mapping = dict(zip(unique_stratification1_df['StratificationID1'], unique_stratification1_df['Stratification1']))\n",
    "\n",
    "# Applying the mapping to create a new column with descriptions\n",
    "df_cleaned['stratification1'] = df_cleaned['StratificationID1'].map(stratification1_mapping)\n",
    "unique_stratification1_df = unique_stratification1_df.rename(columns={'StratificationID1': 'stratification1_id', 'Stratification1': 'stratification1'})\n",
    "unique_stratification1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_stratification_df = df_cleaned.groupby([\"Stratification1\", \"StratificationCategory2\", \"Stratification2\"])['Stratification2'].agg(unique_values='unique')\n",
    "unique_stratification_df.index.names = [\"Stratification1\", \"Stratification2\", \"StratificationCategory2\"]\n",
    "unique_stratification_df.reset_index(inplace=True)\n",
    "unique_stratification_df = unique_stratification_df.drop(columns=['unique_values'])\n",
    "\n",
    "# Create 'stratification_id' column\n",
    "unique_stratification_df['stratification_id'] = unique_stratification_df.index\n",
    "\n",
    "# Rename 'StratificationCategory2' to 'stratification_category2' and other columns\n",
    "unique_stratification_df.rename(columns={'StratificationCategory2': 'stratification_category2','Stratification1':'stratification1','Stratification2':'stratification2'}, inplace=True)\n",
    "\n",
    "# Reset index to make 'stratification_id' a regular column\n",
    "unique_stratification_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "new_order = [\"stratification_id\", \"stratification1\", \"stratification2\", \"stratification_category2\"]\n",
    "unique_stratification_df = unique_stratification_df[new_order]\n",
    "unique_stratification_df['stratification_id'] = unique_stratification_df['stratification_id'].astype(int)\n",
    "unique_stratification_df['stratification1'] = unique_stratification_df['stratification1'].astype(str)\n",
    "unique_stratification_df['stratification2'] = unique_stratification_df['stratification2'].astype(str)\n",
    "unique_stratification_df['stratification_category2'] = unique_stratification_df['stratification_category2'].astype(str)\n",
    "\n",
    "# Display the DataFrame\n",
    "unique_stratification_df\n",
    "\n",
    "if 'stratification_id' not in df_cleaned.columns:\n",
    "    # Extract 'stratification_id' from unique_stratification_df\n",
    "    extracted_col = unique_stratification_df[\"stratification_id\"]\n",
    "    # Concatenate the extracted column to df_cleaned\n",
    "    df_cleaned = pd.concat([df_cleaned, extracted_col], axis=1)\n",
    "\n",
    "df_cleaned['YearStart'] = df_cleaned['YearStart'].astype('Int64')\n",
    "df_cleaned['YearEnd'] = df_cleaned['YearEnd'].astype('Int64')\n",
    "df_cleaned['LocationID'] = df_cleaned['LocationID'].astype('Int64')\n",
    "\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_df = pd.merge(percent_df, unique_stratification_df, on=[\"stratification1\", \"stratification2\", \"stratification_category2\"], how=\"left\")\n",
    "\n",
    "# Drop the original Stratification columns\n",
    "percent_df.drop(columns=[\"stratification1\", \"stratification2\", \"stratification_category2\"], inplace=True)\n",
    "\n",
    "# Drop duplicates if any\n",
    "percent_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Reset index\n",
    "percent_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "percent_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
